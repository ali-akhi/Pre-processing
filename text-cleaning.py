# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DnPAy7ownASpx4HMWCFWjwCAntUXMC2g
"""

from google.colab import drive
import numpy as np
import pandas as pd
import neattext as nt
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import contractions
import neattext.functions as nfx
nltk.download('stopwords')

"""drive mount"""

drive.mount('/content/drive')
path= '/content/drive/MyDrive/clean-data.csv'

"""functions"""

#function for read data frame

def read_df(path):
    content=pd.read_csv(path)
    return content

#function for remeve stopwords

def remove_stopwords(content):
    return content.remove_stopwords()

#function for hard remove stopwords 

def hard_remove_stopwords(content):
    return content.remove_stopwords().text

#funciton for remove punctions 

def remove_punctions(content):
    return content.remove_puncts(most_common=False).text

#function for hard remove punctions

def hard_remove_punctions(content):
    return content.remove_puncts(most_common=True).text

#function for remove userhandless

def remove_userhandles(content):
    return nfx.remove_userhandles(content)

#function for remove hashtags

def remove_hashtags(content):
    return nfx.remove_hashtags(content)

#function for remove special char

def remove_special_char(content):
    return nfx.remove_special_characters(content)

#function for stemming

def stemming(content):
    stemmed_content= re.sub('[^a-zA-Z]', ' ', content)
    stemmed_content= stemmed_content.lower()
    stemmed_content= stemmed_content.split()
    stemmed_content= [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
    return stemmed_content

#function for remove custom pattern

def remove_with_pattern(content):
  return nfx.remove_custom_pattern(content, term_pattern= r'^[0-9]{0,2}+$')

#functio for remove multiple space

def remove_spaces(content):
  return nfx.remove_multiple_spaces(content)

#function for contractions

def contrac(content):
  contractions.fix(content)
  nfx.fix_contractions(content)

#function for clean text with all task

def clean_texting(content):
  return nfx.clean_text(content, puncts=False, stopwords=True, urls=True, emails=True, numbers=True, emojis=False, special_char=True)

#function for Noise svan

def noise_scaning(content):
  noise= content['message'].apply(lambda x:nt.TextFrame(x).noise_scan())
  return noise

#save csv data frame

def save_csv(extention, name, df):
  full_name= name + '.' + extention
  csv_name= name + '.' + 'csv'
  compression_opts = dict(method=extention,
                        archive_name=csv_name)  
  df.to_csv(full_name, index=False,
          compression=compression_opts)

"""read content"""

dataframe= read_df(path)
old_message= dataframe.loc[8]['message']
old_message
noise_scaning(dataframe)

"""test"""

dataframe['message']= dataframe['message'].apply(clean_texting, contrac)
dataframe['message']= dataframe['message'].apply(remove_spaces)
save_csv('zip', 'clean-text', dataframe)
# = dataframe.loc[8]['message']
# test
# noise_scaning(dataframe)